{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/software/anaconda3/envs/kan/lib/python3.9/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment HalfCheetah-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/daniel/software/anaconda3/envs/kan/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py:190: UserWarning: \u001b[33mWARN: This version of the mujoco environments depends on the mujoco-py bindings, which are no longer maintained and may stop working. Please upgrade to the v4 versions of the environments (which depend on the mujoco python bindings instead), unless you are trying to precisely replicate previous works).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created\n",
      "created\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41966/2374976894.py:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  tensor_o1 = torch.Tensor(traj1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle as pkl\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from pref_kan.oracle import HumanCritic\n",
    "from pref_kan.kan_oracle import HumanCritic as HumanCriticKan\n",
    "\n",
    "def load_pickle(name):\n",
    "    with open(name + \".pkl\", 'rb') as handle:\n",
    "        return pkl.load(handle)\n",
    "\n",
    "def generate_data_for_training_with_critical_points(queries):\n",
    "    queries = np.array(queries, dtype=object)\n",
    "    o1, o2, prefs = queries[:, 0, 0], queries[:, 1, 0], queries[:, 2]\n",
    "    o1 = [np.stack(segments) for segments in o1]\n",
    "    o2 = [np.stack(segments) for segments in o2]\n",
    "    prefs = np.asarray(prefs).astype('float32')\n",
    "    return o1, o2, prefs\n",
    "\n",
    "def create_dataloader(pairs):\n",
    "\n",
    "    traj1, traj2, prefs = generate_data_for_training_with_critical_points(pairs)\n",
    "    tensor_o1 = torch.Tensor(traj1)\n",
    "    tensor_o2 = torch.Tensor(traj2)\n",
    "    tensor_prefs = torch.Tensor(prefs)\n",
    "    my_dataset = TensorDataset(tensor_o1, tensor_o2, tensor_prefs)\n",
    "    my_dataloader = DataLoader(my_dataset, batch_size=128, shuffle=True)\n",
    "    return my_dataloader\n",
    "\n",
    "def test_accuracy(dataset, oracle):\n",
    "    total_params = sum(p.numel() for p in oracle.reward_model.parameters())\n",
    "    for step, (o1, o2, prefs) in enumerate(dataset):\n",
    "            o1 = o1.to('cpu')  # Move input tensors to the device\n",
    "            o2 = o2.to('cpu')\n",
    "            prefs = prefs.to('cpu')\n",
    "            o1_unrolled = torch.reshape(o1, [-1, oracle.obs_size[0] + oracle.action_size])\n",
    "            o2_unrolled = torch.reshape(o2, [-1, oracle.obs_size[0] + oracle.action_size])\n",
    "            r1_unrolled = oracle.reward_model(o1_unrolled)\n",
    "            r2_unrolled = oracle.reward_model(o2_unrolled)\n",
    "\n",
    "            r1_rolled = torch.reshape(r1_unrolled, o1.shape[0:2])\n",
    "            r2_rolled = torch.reshape(r2_unrolled, o2.shape[0:2])\n",
    "\n",
    "            rs1 = torch.sum(r1_rolled, dim=1)\n",
    "            rs2 = torch.sum(r2_rolled, dim=1)\n",
    "            rss = torch.stack([rs1, rs2])\n",
    "            rss = torch.t(rss)\n",
    "\n",
    "            preds = torch.softmax(rss, dim=0)\n",
    "            preds_correct = torch.eq(torch.argmax(prefs, 1), torch.argmax(preds, 1)).type(torch.float32)\n",
    "            accuracy = torch.mean(preds_correct)\n",
    "\n",
    "\n",
    "    return accuracy.item(), total_params        \n",
    "\n",
    "env_id = \"HalfCheetah-v3\"\n",
    "data_set_name = \"/../data/cheetah/rl_zoopairs_cheetahbuffer\"\n",
    "sizes_data_set_name = \"/../data/cheetah/rl_zoopairs_size_cheetahbuffer\"\n",
    "path = os.getcwd()\n",
    "\n",
    "pairs = load_pickle(path + data_set_name)\n",
    "pairs_size = load_pickle(path + sizes_data_set_name)\n",
    "\n",
    "env = gym.make(env_id)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = env.action_space.shape[0]\n",
    "oracle = HumanCritic(state_size, action_size,hidden_sizes=(64,64), training_epochs=200,seed=123)\n",
    "oracle_kan = HumanCriticKan(state_size,action_size,hidden_sizes=(6,2), training_epochs=200,seed=123)\n",
    "\n",
    "training_pairs = [pairs[idx] for idx in range(pairs_size-10)]\n",
    "training_dataloader = create_dataloader(training_pairs)\n",
    "\n",
    "test_pairs = [pairs[idx] for idx in range(pairs_size-10, pairs_size)]\n",
    "test_dataloader = create_dataloader(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created\n",
      "created\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m accuracy_mlp, params_mlp \u001b[38;5;241m=\u001b[39m test_accuracy(test_dataloader, oracle)\n\u001b[1;32m      9\u001b[0m accuracy_kan, params_kan \u001b[38;5;241m=\u001b[39m test_accuracy(test_dataloader, oracle_kan)\n\u001b[0;32m---> 10\u001b[0m accuracy_mlp_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(accuracy_mlp\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m accuracy_kan_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(accuracy_kan\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy so far KAN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_kan_list\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m MLP:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_mlp_list\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "seed_list = [1,5,123,1234]\n",
    "accuracy_mlp_list, accuracy_kan_list = [], []\n",
    "for seed in seed_list:\n",
    "    oracle = HumanCritic(state_size, action_size,hidden_sizes=(64,64), training_epochs=200,seed=seed, verbose=False)\n",
    "    oracle_kan = HumanCriticKan(state_size,action_size,hidden_sizes=(6,2), training_epochs=200,seed=seed, verbose=False)\n",
    "    oracle.train_dataset(training_dataloader, {})\n",
    "    oracle_kan.train_dataset(training_dataloader, {})\n",
    "    accuracy_mlp, params_mlp = test_accuracy(test_dataloader, oracle)\n",
    "    accuracy_kan, params_kan = test_accuracy(test_dataloader, oracle_kan)\n",
    "    accuracy_mlp_list.append(round(accuracy_mlp*100,1))\n",
    "    accuracy_kan_list.append(round(accuracy_kan*100,1))\n",
    "    print(f\"Accuracy so far KAN: {accuracy_kan_list} \\n MLP:{accuracy_mlp_list}\")\n",
    "print(f\"MLP mean accuracy: {np.mean(accuracy_mlp_list)} \\n KAN mean accuracy: {np.mean(accuracy_kan_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
